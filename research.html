---
title: Research
---

<p>I'm currently interested in interpretable NLP as applied to program synthesis language models. 
    My recent publications leverage notions from formal verification (e.g. Hoare triples) to ground program synthesis.
</p>

<div class="row">
    <div class="col-md-12">
        
          <h4 class="text-left"><a href="https://aclanthology.org/2023.findings-emnlp.601/">Natural Language Annotations for Reasoning about Program Semantics</a></h4>
          <i class="text-left">EMNLP (Findings) 2023</i>
          <p class="text-left">We propose a dataset and protocol for annotating programs with natural language predicates at a finer granularity 
            than code comments and without relying on internal compiler representations.</p>
        
    </div>
</div>

<div class="row">
    <div class="col-md-12">
          <h4 class="text-left"><a href="https://arxiv.org/abs/2305.06161">StarCoder: may the source be with you!</a></h4>
          <i class="text-left">Transactions on Machine Learning Research (12/2023)</i>
          <p class="text-left">The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 
            15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. </p>
    </div>
</div>